{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNTrZFV0J8TgfN/bPH2VTFv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["**The main content of this article will present how the AlexNet Convolutional Neural Network(CNN) architecture is implemented using TensorFlow and Keras.**"],"metadata":{"id":"-Mrg8f3vXx1m"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tDQVUHmZXHXb"},"outputs":[],"source":["import keras\n","from keras.datasets import cifar10\n","from keras import backend as K\n","from keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dense, BatchNormalization, Activation, MaxPooling2D\n","from keras.models import Model\n","from keras.layers import concatenate,Dropout,Flatten\n","\n","from keras import optimizers,regularizers\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.initializers import he_normal\n","from keras.callbacks import LearningRateScheduler, TensorBoard, ModelCheckpoint\n","\n","num_classes        = 10\n","batch_size         = 64\n","iterations         = 782\n","epochs             = 300\n","DROPOUT=0.5\n","CONCAT_AXIS=3\n","weight_decay=1e-4\n","DATA_FORMAT='channels_last'\n","log_filepath  = './alexnet'"]},{"cell_type":"code","source":["def color_preprocessing(x_train,x_test):\n","    x_train = x_train.astype('float32')\n","    x_test = x_test.astype('float32')\n","    mean = [125.307, 122.95, 113.865]\n","    std  = [62.9932, 62.0887, 66.7048]\n","    for i in range(3):\n","        x_train[:,:,:,i] = (x_train[:,:,:,i] - mean[i]) / std[i]\n","        x_test[:,:,:,i] = (x_test[:,:,:,i] - mean[i]) / std[i]\n","    return x_train, x_test\n","\n","def scheduler(epoch):\n","    if epoch < 100:\n","        return 0.01\n","    if epoch < 200:\n","        return 0.001\n","    return 0.0001\n","\n","# load data\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test  = keras.utils.to_categorical(y_test, num_classes)\n","x_train, x_test = color_preprocessing(x_train, x_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jjr9ymX_XhQF","executionInfo":{"status":"ok","timestamp":1715795756963,"user_tz":-480,"elapsed":6282,"user":{"displayName":"Chunting LI","userId":"05063483228806240574"}},"outputId":"103fa8d8-64b5-49e4-f36d-9a367c65c81a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170498071/170498071 [==============================] - 2s 0us/step\n"]}]},{"cell_type":"code","source":["def alexnet(img_input,classes=10):\n","    x = Conv2D(96,(11,11),strides=(4,4),padding='same',\n","               activation='relu',kernel_initializer='uniform')(img_input)# valid\n","    x = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same',data_format=DATA_FORMAT)(x)\n","\n","    x = Conv2D(256,(5,5),strides=(1,1),padding='same',\n","               activation='relu',kernel_initializer='uniform')(x)\n","    x = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same',data_format=DATA_FORMAT)(x)\n","\n","    x = Conv2D(384,(3,3),strides=(1,1),padding='same',\n","               activation='relu',kernel_initializer='uniform')(x)\n","\n","    x = Conv2D(384,(3,3),strides=(1,1),padding='same',\n","               activation='relu',kernel_initializer='uniform')(x)\n","\n","    x = Conv2D(256,(3,3),strides=(1,1),padding='same',\n","               activation='relu',kernel_initializer='uniform')(x)\n","    x = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same',data_format=DATA_FORMAT)(x)\n","    x = Flatten()(x)\n","    x = Dense(4096,activation='relu')(x)\n","    x = Dropout(0.5)(x)\n","    x = Dense(4096,activation='relu')(x)\n","    x = Dropout(0.5)(x)\n","    out = Dense(classes, activation='softmax')(x)\n","    return out"],"metadata":{"id":"rLY0cMgjZI4g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img_input=Input(shape=(32,32,3))\n","output = alexnet(img_input)\n","model=Model(img_input,output)\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Zxqa7I7ZO2o","executionInfo":{"status":"ok","timestamp":1715795774011,"user_tz":-480,"elapsed":436,"user":{"displayName":"Chunting LI","userId":"05063483228806240574"}},"outputId":"122d4a59-4feb-401d-d18a-9407a59b4732"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 8, 8, 96)          34944     \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 4, 4, 96)          0         \n"," D)                                                              \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 4, 4, 256)         614656    \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  (None, 2, 2, 256)         0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 2, 2, 384)         885120    \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 2, 2, 384)         1327488   \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 2, 2, 256)         884992    \n","                                                                 \n"," max_pooling2d_2 (MaxPoolin  (None, 1, 1, 256)         0         \n"," g2D)                                                            \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 4096)              1052672   \n","                                                                 \n"," dropout (Dropout)           (None, 4096)              0         \n","                                                                 \n"," dense_1 (Dense)             (None, 4096)              16781312  \n","                                                                 \n"," dropout_1 (Dropout)         (None, 4096)              0         \n","                                                                 \n"," dense_2 (Dense)             (None, 10)                40970     \n","                                                                 \n","=================================================================\n","Total params: 21622154 (82.48 MB)\n","Trainable params: 21622154 (82.48 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# set optimizer\n","sgd = optimizers.SGD(learning_rate=.1, momentum=0.9, nesterov=True)\n","model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","\n","# set callback\n","tb_cb = TensorBoard(log_dir=log_filepath, histogram_freq=0)\n","change_lr = LearningRateScheduler(scheduler)\n","cbks = [change_lr,tb_cb]\n","\n","# set data augmentation\n","datagen = ImageDataGenerator(horizontal_flip=True,\n","                             width_shift_range=0.125,\n","                             height_shift_range=0.125,\n","                             fill_mode='constant',cval=0.)\n","\n","#horizontal_flip=True Randomly flip inputs horizontally.\n","# width_shift_range=0.125\n","#height_shift_range=0.125\n","#fill_mode='constant',cval=0 'constant': kkkkkkkk|abcd|kkkkkkkk (cval=k)\n","datagen.fit(x_train)\n","\n","# start training\n","model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),\n","                    steps_per_epoch=iterations,\n","                    epochs=epochs,\n","                    callbacks=cbks,\n","                    validation_data=(x_test, y_test))\n","model.save('alexnet.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4W9yvP7TZQYQ","outputId":"b517f51d-3d88-4ee1-9235-b82bff621ca4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n","<ipython-input-6-8f2c7a66eecc>:23: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/300\n","782/782 [==============================] - 38s 42ms/step - loss: 1.7030 - accuracy: 0.3667 - val_loss: 1.4709 - val_accuracy: 0.4765 - lr: 0.0100\n","Epoch 2/300\n","782/782 [==============================] - 31s 40ms/step - loss: 1.4068 - accuracy: 0.4935 - val_loss: 1.2931 - val_accuracy: 0.5464 - lr: 0.0100\n","Epoch 3/300\n","782/782 [==============================] - 32s 41ms/step - loss: 1.2784 - accuracy: 0.5429 - val_loss: 1.1580 - val_accuracy: 0.5978 - lr: 0.0100\n","Epoch 4/300\n","782/782 [==============================] - 31s 40ms/step - loss: 1.1956 - accuracy: 0.5738 - val_loss: 1.1225 - val_accuracy: 0.6162 - lr: 0.0100\n","Epoch 5/300\n","782/782 [==============================] - 31s 39ms/step - loss: 1.1325 - accuracy: 0.6012 - val_loss: 1.0406 - val_accuracy: 0.6377 - lr: 0.0100\n","Epoch 6/300\n","782/782 [==============================] - 32s 41ms/step - loss: 1.0734 - accuracy: 0.6228 - val_loss: 1.0441 - val_accuracy: 0.6372 - lr: 0.0100\n","Epoch 7/300\n","782/782 [==============================] - 32s 41ms/step - loss: 1.0382 - accuracy: 0.6340 - val_loss: 0.9614 - val_accuracy: 0.6694 - lr: 0.0100\n","Epoch 8/300\n","782/782 [==============================] - 31s 39ms/step - loss: 0.9991 - accuracy: 0.6504 - val_loss: 0.9525 - val_accuracy: 0.6623 - lr: 0.0100\n","Epoch 9/300\n","782/782 [==============================] - 32s 40ms/step - loss: 0.9673 - accuracy: 0.6605 - val_loss: 0.9037 - val_accuracy: 0.6887 - lr: 0.0100\n","Epoch 10/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.9374 - accuracy: 0.6710 - val_loss: 0.9650 - val_accuracy: 0.6687 - lr: 0.0100\n","Epoch 11/300\n","782/782 [==============================] - 30s 39ms/step - loss: 0.9134 - accuracy: 0.6810 - val_loss: 0.9462 - val_accuracy: 0.6825 - lr: 0.0100\n","Epoch 12/300\n","782/782 [==============================] - 32s 42ms/step - loss: 0.8872 - accuracy: 0.6891 - val_loss: 0.9045 - val_accuracy: 0.6905 - lr: 0.0100\n","Epoch 13/300\n","782/782 [==============================] - 35s 44ms/step - loss: 0.8651 - accuracy: 0.6966 - val_loss: 0.8685 - val_accuracy: 0.6999 - lr: 0.0100\n","Epoch 14/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.8435 - accuracy: 0.7055 - val_loss: 0.8617 - val_accuracy: 0.7058 - lr: 0.0100\n","Epoch 15/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.8264 - accuracy: 0.7111 - val_loss: 0.8377 - val_accuracy: 0.7126 - lr: 0.0100\n","Epoch 16/300\n","782/782 [==============================] - 34s 43ms/step - loss: 0.8069 - accuracy: 0.7168 - val_loss: 0.8729 - val_accuracy: 0.7027 - lr: 0.0100\n","Epoch 17/300\n","782/782 [==============================] - 33s 42ms/step - loss: 0.7870 - accuracy: 0.7248 - val_loss: 0.8297 - val_accuracy: 0.7160 - lr: 0.0100\n","Epoch 18/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.7715 - accuracy: 0.7302 - val_loss: 0.8179 - val_accuracy: 0.7201 - lr: 0.0100\n","Epoch 19/300\n","782/782 [==============================] - 33s 42ms/step - loss: 0.7542 - accuracy: 0.7348 - val_loss: 0.8417 - val_accuracy: 0.7132 - lr: 0.0100\n","Epoch 20/300\n","782/782 [==============================] - 34s 43ms/step - loss: 0.7431 - accuracy: 0.7376 - val_loss: 0.9130 - val_accuracy: 0.6963 - lr: 0.0100\n","Epoch 21/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.7260 - accuracy: 0.7450 - val_loss: 0.8093 - val_accuracy: 0.7237 - lr: 0.0100\n","Epoch 22/300\n","782/782 [==============================] - 34s 43ms/step - loss: 0.7022 - accuracy: 0.7545 - val_loss: 0.8607 - val_accuracy: 0.7140 - lr: 0.0100\n","Epoch 23/300\n","782/782 [==============================] - 34s 44ms/step - loss: 0.6948 - accuracy: 0.7544 - val_loss: 0.8223 - val_accuracy: 0.7177 - lr: 0.0100\n","Epoch 24/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.6827 - accuracy: 0.7599 - val_loss: 0.7913 - val_accuracy: 0.7274 - lr: 0.0100\n","Epoch 25/300\n","782/782 [==============================] - 33s 43ms/step - loss: 0.6722 - accuracy: 0.7643 - val_loss: 0.8104 - val_accuracy: 0.7261 - lr: 0.0100\n","Epoch 26/300\n","782/782 [==============================] - 33s 42ms/step - loss: 0.6577 - accuracy: 0.7665 - val_loss: 0.8035 - val_accuracy: 0.7282 - lr: 0.0100\n","Epoch 27/300\n","782/782 [==============================] - 31s 39ms/step - loss: 0.6453 - accuracy: 0.7735 - val_loss: 0.7945 - val_accuracy: 0.7317 - lr: 0.0100\n","Epoch 28/300\n","782/782 [==============================] - 30s 39ms/step - loss: 0.6343 - accuracy: 0.7759 - val_loss: 0.8251 - val_accuracy: 0.7230 - lr: 0.0100\n","Epoch 29/300\n","782/782 [==============================] - 33s 42ms/step - loss: 0.6252 - accuracy: 0.7787 - val_loss: 0.8164 - val_accuracy: 0.7253 - lr: 0.0100\n","Epoch 30/300\n","782/782 [==============================] - 31s 40ms/step - loss: 0.6105 - accuracy: 0.7858 - val_loss: 0.8110 - val_accuracy: 0.7300 - lr: 0.0100\n","Epoch 31/300\n","782/782 [==============================] - 30s 39ms/step - loss: 0.6010 - accuracy: 0.7873 - val_loss: 0.8046 - val_accuracy: 0.7317 - lr: 0.0100\n","Epoch 32/300\n","782/782 [==============================] - 33s 42ms/step - loss: 0.5833 - accuracy: 0.7913 - val_loss: 0.8072 - val_accuracy: 0.7368 - lr: 0.0100\n","Epoch 33/300\n","782/782 [==============================] - 30s 39ms/step - loss: 0.5807 - accuracy: 0.7958 - val_loss: 0.7908 - val_accuracy: 0.7370 - lr: 0.0100\n","Epoch 34/300\n","782/782 [==============================] - 31s 40ms/step - loss: 0.5666 - accuracy: 0.7976 - val_loss: 0.8180 - val_accuracy: 0.7344 - lr: 0.0100\n","Epoch 35/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.5597 - accuracy: 0.8027 - val_loss: 0.8104 - val_accuracy: 0.7421 - lr: 0.0100\n","Epoch 36/300\n","782/782 [==============================] - 30s 39ms/step - loss: 0.5470 - accuracy: 0.8058 - val_loss: 0.8129 - val_accuracy: 0.7423 - lr: 0.0100\n","Epoch 37/300\n","782/782 [==============================] - 33s 42ms/step - loss: 0.5367 - accuracy: 0.8098 - val_loss: 0.8214 - val_accuracy: 0.7338 - lr: 0.0100\n","Epoch 38/300\n","782/782 [==============================] - 30s 39ms/step - loss: 0.5258 - accuracy: 0.8143 - val_loss: 0.8104 - val_accuracy: 0.7408 - lr: 0.0100\n","Epoch 39/300\n","782/782 [==============================] - 30s 39ms/step - loss: 0.5233 - accuracy: 0.8130 - val_loss: 0.8104 - val_accuracy: 0.7376 - lr: 0.0100\n","Epoch 40/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.5044 - accuracy: 0.8209 - val_loss: 0.7964 - val_accuracy: 0.7413 - lr: 0.0100\n","Epoch 41/300\n","782/782 [==============================] - 31s 40ms/step - loss: 0.4992 - accuracy: 0.8221 - val_loss: 0.8703 - val_accuracy: 0.7293 - lr: 0.0100\n","Epoch 42/300\n","782/782 [==============================] - 34s 43ms/step - loss: 0.4928 - accuracy: 0.8250 - val_loss: 0.8122 - val_accuracy: 0.7481 - lr: 0.0100\n","Epoch 43/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.4793 - accuracy: 0.8285 - val_loss: 0.8327 - val_accuracy: 0.7387 - lr: 0.0100\n","Epoch 44/300\n","782/782 [==============================] - 30s 39ms/step - loss: 0.4740 - accuracy: 0.8314 - val_loss: 0.8126 - val_accuracy: 0.7401 - lr: 0.0100\n","Epoch 45/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.4695 - accuracy: 0.8333 - val_loss: 0.8298 - val_accuracy: 0.7390 - lr: 0.0100\n","Epoch 46/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.4570 - accuracy: 0.8369 - val_loss: 0.8483 - val_accuracy: 0.7363 - lr: 0.0100\n","Epoch 47/300\n","782/782 [==============================] - 31s 39ms/step - loss: 0.4473 - accuracy: 0.8429 - val_loss: 0.8342 - val_accuracy: 0.7390 - lr: 0.0100\n","Epoch 48/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.4401 - accuracy: 0.8463 - val_loss: 0.8353 - val_accuracy: 0.7433 - lr: 0.0100\n","Epoch 49/300\n","782/782 [==============================] - 31s 39ms/step - loss: 0.4365 - accuracy: 0.8458 - val_loss: 0.8224 - val_accuracy: 0.7477 - lr: 0.0100\n","Epoch 50/300\n","782/782 [==============================] - 35s 45ms/step - loss: 0.4314 - accuracy: 0.8475 - val_loss: 0.8498 - val_accuracy: 0.7444 - lr: 0.0100\n","Epoch 51/300\n","782/782 [==============================] - 34s 43ms/step - loss: 0.4198 - accuracy: 0.8502 - val_loss: 0.8610 - val_accuracy: 0.7346 - lr: 0.0100\n","Epoch 52/300\n","782/782 [==============================] - 34s 43ms/step - loss: 0.4165 - accuracy: 0.8529 - val_loss: 0.8577 - val_accuracy: 0.7325 - lr: 0.0100\n","Epoch 53/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.4158 - accuracy: 0.8532 - val_loss: 0.8204 - val_accuracy: 0.7457 - lr: 0.0100\n","Epoch 54/300\n","782/782 [==============================] - 33s 43ms/step - loss: 0.4038 - accuracy: 0.8577 - val_loss: 0.8195 - val_accuracy: 0.7491 - lr: 0.0100\n","Epoch 55/300\n","782/782 [==============================] - 33s 42ms/step - loss: 0.3915 - accuracy: 0.8605 - val_loss: 0.8837 - val_accuracy: 0.7335 - lr: 0.0100\n","Epoch 56/300\n","782/782 [==============================] - 33s 43ms/step - loss: 0.3832 - accuracy: 0.8673 - val_loss: 0.8741 - val_accuracy: 0.7399 - lr: 0.0100\n","Epoch 57/300\n","782/782 [==============================] - 34s 43ms/step - loss: 0.3809 - accuracy: 0.8663 - val_loss: 0.8555 - val_accuracy: 0.7452 - lr: 0.0100\n","Epoch 58/300\n","782/782 [==============================] - 35s 45ms/step - loss: 0.3717 - accuracy: 0.8703 - val_loss: 0.9356 - val_accuracy: 0.7375 - lr: 0.0100\n","Epoch 59/300\n","782/782 [==============================] - 33s 42ms/step - loss: 0.3620 - accuracy: 0.8721 - val_loss: 0.9089 - val_accuracy: 0.7400 - lr: 0.0100\n","Epoch 60/300\n","782/782 [==============================] - 34s 44ms/step - loss: 0.3566 - accuracy: 0.8753 - val_loss: 0.9012 - val_accuracy: 0.7402 - lr: 0.0100\n","Epoch 61/300\n","782/782 [==============================] - 35s 44ms/step - loss: 0.3517 - accuracy: 0.8767 - val_loss: 0.9105 - val_accuracy: 0.7381 - lr: 0.0100\n","Epoch 62/300\n","782/782 [==============================] - 33s 42ms/step - loss: 0.3482 - accuracy: 0.8780 - val_loss: 0.8739 - val_accuracy: 0.7450 - lr: 0.0100\n","Epoch 63/300\n","782/782 [==============================] - 34s 43ms/step - loss: 0.3517 - accuracy: 0.8762 - val_loss: 0.8804 - val_accuracy: 0.7353 - lr: 0.0100\n","Epoch 64/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.3414 - accuracy: 0.8799 - val_loss: 0.8846 - val_accuracy: 0.7402 - lr: 0.0100\n","Epoch 65/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.3367 - accuracy: 0.8836 - val_loss: 0.8736 - val_accuracy: 0.7331 - lr: 0.0100\n","Epoch 66/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.3340 - accuracy: 0.8839 - val_loss: 0.8709 - val_accuracy: 0.7421 - lr: 0.0100\n","Epoch 67/300\n","782/782 [==============================] - 31s 39ms/step - loss: 0.3226 - accuracy: 0.8881 - val_loss: 0.9081 - val_accuracy: 0.7385 - lr: 0.0100\n","Epoch 68/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.3206 - accuracy: 0.8885 - val_loss: 0.8920 - val_accuracy: 0.7410 - lr: 0.0100\n","Epoch 69/300\n","782/782 [==============================] - 31s 40ms/step - loss: 0.3145 - accuracy: 0.8899 - val_loss: 0.9224 - val_accuracy: 0.7390 - lr: 0.0100\n","Epoch 70/300\n","782/782 [==============================] - 32s 42ms/step - loss: 0.3114 - accuracy: 0.8903 - val_loss: 0.9248 - val_accuracy: 0.7401 - lr: 0.0100\n","Epoch 71/300\n","782/782 [==============================] - 33s 42ms/step - loss: 0.3158 - accuracy: 0.8909 - val_loss: 0.8978 - val_accuracy: 0.7356 - lr: 0.0100\n","Epoch 72/300\n","782/782 [==============================] - 31s 39ms/step - loss: 0.3060 - accuracy: 0.8939 - val_loss: 0.9308 - val_accuracy: 0.7359 - lr: 0.0100\n","Epoch 73/300\n","782/782 [==============================] - 33s 42ms/step - loss: 0.2979 - accuracy: 0.8977 - val_loss: 0.9077 - val_accuracy: 0.7394 - lr: 0.0100\n","Epoch 74/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.2935 - accuracy: 0.8990 - val_loss: 0.9175 - val_accuracy: 0.7444 - lr: 0.0100\n","Epoch 75/300\n","782/782 [==============================] - 31s 40ms/step - loss: 0.2913 - accuracy: 0.8991 - val_loss: 0.9013 - val_accuracy: 0.7439 - lr: 0.0100\n","Epoch 76/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.2902 - accuracy: 0.8995 - val_loss: 0.8992 - val_accuracy: 0.7438 - lr: 0.0100\n","Epoch 77/300\n","782/782 [==============================] - 31s 40ms/step - loss: 0.2830 - accuracy: 0.9052 - val_loss: 0.9513 - val_accuracy: 0.7373 - lr: 0.0100\n","Epoch 78/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.2782 - accuracy: 0.9049 - val_loss: 0.8914 - val_accuracy: 0.7443 - lr: 0.0100\n","Epoch 79/300\n","782/782 [==============================] - 33s 42ms/step - loss: 0.2738 - accuracy: 0.9050 - val_loss: 0.9202 - val_accuracy: 0.7398 - lr: 0.0100\n","Epoch 80/300\n","782/782 [==============================] - 35s 44ms/step - loss: 0.2752 - accuracy: 0.9058 - val_loss: 0.9794 - val_accuracy: 0.7347 - lr: 0.0100\n","Epoch 81/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.2663 - accuracy: 0.9104 - val_loss: 0.9312 - val_accuracy: 0.7392 - lr: 0.0100\n","Epoch 82/300\n","782/782 [==============================] - 31s 39ms/step - loss: 0.2633 - accuracy: 0.9104 - val_loss: 1.0410 - val_accuracy: 0.7285 - lr: 0.0100\n","Epoch 83/300\n","782/782 [==============================] - 31s 40ms/step - loss: 0.2676 - accuracy: 0.9091 - val_loss: 0.9210 - val_accuracy: 0.7410 - lr: 0.0100\n","Epoch 84/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.2612 - accuracy: 0.9117 - val_loss: 0.9824 - val_accuracy: 0.7408 - lr: 0.0100\n","Epoch 85/300\n","782/782 [==============================] - 31s 40ms/step - loss: 0.2629 - accuracy: 0.9121 - val_loss: 0.9787 - val_accuracy: 0.7343 - lr: 0.0100\n","Epoch 86/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.2543 - accuracy: 0.9147 - val_loss: 0.9401 - val_accuracy: 0.7380 - lr: 0.0100\n","Epoch 87/300\n","782/782 [==============================] - 31s 39ms/step - loss: 0.2524 - accuracy: 0.9142 - val_loss: 0.9435 - val_accuracy: 0.7386 - lr: 0.0100\n","Epoch 88/300\n","782/782 [==============================] - 31s 40ms/step - loss: 0.2484 - accuracy: 0.9178 - val_loss: 1.0057 - val_accuracy: 0.7322 - lr: 0.0100\n","Epoch 89/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.2564 - accuracy: 0.9144 - val_loss: 0.9801 - val_accuracy: 0.7283 - lr: 0.0100\n","Epoch 90/300\n","782/782 [==============================] - 31s 40ms/step - loss: 0.2478 - accuracy: 0.9156 - val_loss: 0.9716 - val_accuracy: 0.7340 - lr: 0.0100\n","Epoch 91/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.2483 - accuracy: 0.9166 - val_loss: 0.9432 - val_accuracy: 0.7466 - lr: 0.0100\n","Epoch 92/300\n","782/782 [==============================] - 31s 40ms/step - loss: 0.2450 - accuracy: 0.9182 - val_loss: 0.9854 - val_accuracy: 0.7333 - lr: 0.0100\n","Epoch 93/300\n","782/782 [==============================] - 33s 42ms/step - loss: 0.2340 - accuracy: 0.9217 - val_loss: 0.9932 - val_accuracy: 0.7328 - lr: 0.0100\n","Epoch 94/300\n","782/782 [==============================] - 34s 43ms/step - loss: 0.2338 - accuracy: 0.9217 - val_loss: 0.9669 - val_accuracy: 0.7345 - lr: 0.0100\n","Epoch 95/300\n","782/782 [==============================] - 31s 40ms/step - loss: 0.2265 - accuracy: 0.9239 - val_loss: 1.0135 - val_accuracy: 0.7328 - lr: 0.0100\n","Epoch 96/300\n","782/782 [==============================] - 33s 42ms/step - loss: 0.2429 - accuracy: 0.9205 - val_loss: 0.9750 - val_accuracy: 0.7366 - lr: 0.0100\n","Epoch 97/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.2348 - accuracy: 0.9233 - val_loss: 0.9728 - val_accuracy: 0.7446 - lr: 0.0100\n","Epoch 98/300\n","782/782 [==============================] - 31s 40ms/step - loss: 0.2416 - accuracy: 0.9218 - val_loss: 0.9482 - val_accuracy: 0.7367 - lr: 0.0100\n","Epoch 99/300\n","782/782 [==============================] - 31s 40ms/step - loss: 0.2315 - accuracy: 0.9221 - val_loss: 0.9526 - val_accuracy: 0.7381 - lr: 0.0100\n","Epoch 100/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.2172 - accuracy: 0.9277 - val_loss: 0.9460 - val_accuracy: 0.7381 - lr: 0.0100\n","Epoch 101/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.1531 - accuracy: 0.9498 - val_loss: 0.9777 - val_accuracy: 0.7522 - lr: 0.0010\n","Epoch 102/300\n","782/782 [==============================] - 31s 39ms/step - loss: 0.1107 - accuracy: 0.9636 - val_loss: 1.0283 - val_accuracy: 0.7565 - lr: 0.0010\n","Epoch 103/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.0964 - accuracy: 0.9676 - val_loss: 1.0640 - val_accuracy: 0.7584 - lr: 0.0010\n","Epoch 104/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.0893 - accuracy: 0.9704 - val_loss: 1.0820 - val_accuracy: 0.7606 - lr: 0.0010\n","Epoch 105/300\n","782/782 [==============================] - 30s 39ms/step - loss: 0.0801 - accuracy: 0.9732 - val_loss: 1.1067 - val_accuracy: 0.7586 - lr: 0.0010\n","Epoch 106/300\n","782/782 [==============================] - 32s 40ms/step - loss: 0.0758 - accuracy: 0.9749 - val_loss: 1.1255 - val_accuracy: 0.7575 - lr: 0.0010\n","Epoch 107/300\n","782/782 [==============================] - 32s 40ms/step - loss: 0.0763 - accuracy: 0.9745 - val_loss: 1.1502 - val_accuracy: 0.7574 - lr: 0.0010\n","Epoch 108/300\n","782/782 [==============================] - 31s 40ms/step - loss: 0.0690 - accuracy: 0.9764 - val_loss: 1.1792 - val_accuracy: 0.7573 - lr: 0.0010\n","Epoch 109/300\n","782/782 [==============================] - 33s 42ms/step - loss: 0.0665 - accuracy: 0.9774 - val_loss: 1.2029 - val_accuracy: 0.7591 - lr: 0.0010\n","Epoch 110/300\n","782/782 [==============================] - 30s 39ms/step - loss: 0.0662 - accuracy: 0.9775 - val_loss: 1.1987 - val_accuracy: 0.7576 - lr: 0.0010\n","Epoch 111/300\n","782/782 [==============================] - 33s 42ms/step - loss: 0.0628 - accuracy: 0.9791 - val_loss: 1.2237 - val_accuracy: 0.7569 - lr: 0.0010\n","Epoch 112/300\n","782/782 [==============================] - 31s 39ms/step - loss: 0.0585 - accuracy: 0.9805 - val_loss: 1.2474 - val_accuracy: 0.7584 - lr: 0.0010\n","Epoch 113/300\n","782/782 [==============================] - 33s 42ms/step - loss: 0.0587 - accuracy: 0.9804 - val_loss: 1.2633 - val_accuracy: 0.7576 - lr: 0.0010\n","Epoch 114/300\n","782/782 [==============================] - 32s 42ms/step - loss: 0.0573 - accuracy: 0.9808 - val_loss: 1.2552 - val_accuracy: 0.7563 - lr: 0.0010\n","Epoch 115/300\n","782/782 [==============================] - 31s 40ms/step - loss: 0.0554 - accuracy: 0.9821 - val_loss: 1.2677 - val_accuracy: 0.7575 - lr: 0.0010\n","Epoch 116/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.0575 - accuracy: 0.9810 - val_loss: 1.2634 - val_accuracy: 0.7552 - lr: 0.0010\n","Epoch 117/300\n","782/782 [==============================] - 34s 43ms/step - loss: 0.0545 - accuracy: 0.9818 - val_loss: 1.2707 - val_accuracy: 0.7583 - lr: 0.0010\n","Epoch 118/300\n","782/782 [==============================] - 31s 39ms/step - loss: 0.0505 - accuracy: 0.9838 - val_loss: 1.2911 - val_accuracy: 0.7587 - lr: 0.0010\n","Epoch 119/300\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0490 - accuracy: 0.9837 - val_loss: 1.3012 - val_accuracy: 0.7616 - lr: 0.0010\n","Epoch 120/300\n","782/782 [==============================] - 31s 40ms/step - loss: 0.0507 - accuracy: 0.9831 - val_loss: 1.2983 - val_accuracy: 0.7605 - lr: 0.0010\n","Epoch 121/300\n","782/782 [==============================] - 31s 39ms/step - loss: 0.0494 - accuracy: 0.9838 - val_loss: 1.3084 - val_accuracy: 0.7608 - lr: 0.0010\n","Epoch 122/300\n","782/782 [==============================] - 31s 39ms/step - loss: 0.0480 - accuracy: 0.9841 - val_loss: 1.3036 - val_accuracy: 0.7607 - lr: 0.0010\n","Epoch 123/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.0466 - accuracy: 0.9848 - val_loss: 1.3127 - val_accuracy: 0.7609 - lr: 0.0010\n","Epoch 124/300\n","782/782 [==============================] - 31s 40ms/step - loss: 0.0444 - accuracy: 0.9851 - val_loss: 1.3301 - val_accuracy: 0.7594 - lr: 0.0010\n","Epoch 125/300\n","782/782 [==============================] - 35s 45ms/step - loss: 0.0455 - accuracy: 0.9855 - val_loss: 1.3163 - val_accuracy: 0.7600 - lr: 0.0010\n","Epoch 126/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.0441 - accuracy: 0.9858 - val_loss: 1.3171 - val_accuracy: 0.7618 - lr: 0.0010\n","Epoch 127/300\n","782/782 [==============================] - 31s 40ms/step - loss: 0.0417 - accuracy: 0.9867 - val_loss: 1.3378 - val_accuracy: 0.7600 - lr: 0.0010\n","Epoch 128/300\n","782/782 [==============================] - 33s 42ms/step - loss: 0.0420 - accuracy: 0.9860 - val_loss: 1.3564 - val_accuracy: 0.7595 - lr: 0.0010\n","Epoch 129/300\n","782/782 [==============================] - 31s 40ms/step - loss: 0.0418 - accuracy: 0.9863 - val_loss: 1.3433 - val_accuracy: 0.7620 - lr: 0.0010\n","Epoch 130/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.0397 - accuracy: 0.9868 - val_loss: 1.3605 - val_accuracy: 0.7612 - lr: 0.0010\n","Epoch 131/300\n","782/782 [==============================] - 31s 40ms/step - loss: 0.0412 - accuracy: 0.9862 - val_loss: 1.3454 - val_accuracy: 0.7579 - lr: 0.0010\n","Epoch 132/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.0421 - accuracy: 0.9862 - val_loss: 1.3556 - val_accuracy: 0.7594 - lr: 0.0010\n","Epoch 133/300\n","782/782 [==============================] - 34s 43ms/step - loss: 0.0365 - accuracy: 0.9880 - val_loss: 1.3602 - val_accuracy: 0.7621 - lr: 0.0010\n","Epoch 134/300\n","782/782 [==============================] - 33s 42ms/step - loss: 0.0383 - accuracy: 0.9873 - val_loss: 1.3859 - val_accuracy: 0.7599 - lr: 0.0010\n","Epoch 135/300\n","782/782 [==============================] - 32s 40ms/step - loss: 0.0375 - accuracy: 0.9877 - val_loss: 1.3920 - val_accuracy: 0.7583 - lr: 0.0010\n","Epoch 136/300\n","782/782 [==============================] - 31s 40ms/step - loss: 0.0384 - accuracy: 0.9876 - val_loss: 1.3947 - val_accuracy: 0.7621 - lr: 0.0010\n","Epoch 137/300\n","782/782 [==============================] - 33s 42ms/step - loss: 0.0367 - accuracy: 0.9874 - val_loss: 1.3999 - val_accuracy: 0.7595 - lr: 0.0010\n","Epoch 138/300\n","782/782 [==============================] - 31s 40ms/step - loss: 0.0364 - accuracy: 0.9879 - val_loss: 1.3913 - val_accuracy: 0.7592 - lr: 0.0010\n","Epoch 139/300\n","782/782 [==============================] - 31s 40ms/step - loss: 0.0370 - accuracy: 0.9877 - val_loss: 1.3974 - val_accuracy: 0.7576 - lr: 0.0010\n","Epoch 140/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.0329 - accuracy: 0.9891 - val_loss: 1.4076 - val_accuracy: 0.7566 - lr: 0.0010\n","Epoch 141/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.0332 - accuracy: 0.9889 - val_loss: 1.4256 - val_accuracy: 0.7597 - lr: 0.0010\n","Epoch 142/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.0351 - accuracy: 0.9884 - val_loss: 1.4352 - val_accuracy: 0.7587 - lr: 0.0010\n","Epoch 143/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.0310 - accuracy: 0.9890 - val_loss: 1.4264 - val_accuracy: 0.7580 - lr: 0.0010\n","Epoch 144/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.0351 - accuracy: 0.9885 - val_loss: 1.4503 - val_accuracy: 0.7598 - lr: 0.0010\n","Epoch 145/300\n","782/782 [==============================] - 33s 42ms/step - loss: 0.0333 - accuracy: 0.9894 - val_loss: 1.4488 - val_accuracy: 0.7593 - lr: 0.0010\n","Epoch 146/300\n","782/782 [==============================] - 31s 39ms/step - loss: 0.0327 - accuracy: 0.9894 - val_loss: 1.4336 - val_accuracy: 0.7598 - lr: 0.0010\n","Epoch 147/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.0320 - accuracy: 0.9897 - val_loss: 1.4577 - val_accuracy: 0.7588 - lr: 0.0010\n","Epoch 148/300\n","782/782 [==============================] - 31s 39ms/step - loss: 0.0310 - accuracy: 0.9903 - val_loss: 1.4687 - val_accuracy: 0.7577 - lr: 0.0010\n","Epoch 149/300\n","782/782 [==============================] - 34s 43ms/step - loss: 0.0320 - accuracy: 0.9892 - val_loss: 1.4728 - val_accuracy: 0.7586 - lr: 0.0010\n","Epoch 150/300\n","782/782 [==============================] - 31s 40ms/step - loss: 0.0315 - accuracy: 0.9898 - val_loss: 1.4745 - val_accuracy: 0.7577 - lr: 0.0010\n","Epoch 151/300\n","782/782 [==============================] - 32s 40ms/step - loss: 0.0290 - accuracy: 0.9906 - val_loss: 1.4703 - val_accuracy: 0.7581 - lr: 0.0010\n","Epoch 152/300\n","782/782 [==============================] - 31s 40ms/step - loss: 0.0289 - accuracy: 0.9906 - val_loss: 1.4800 - val_accuracy: 0.7570 - lr: 0.0010\n","Epoch 153/300\n","782/782 [==============================] - 33s 42ms/step - loss: 0.0295 - accuracy: 0.9903 - val_loss: 1.4826 - val_accuracy: 0.7588 - lr: 0.0010\n","Epoch 154/300\n","782/782 [==============================] - 33s 42ms/step - loss: 0.0290 - accuracy: 0.9905 - val_loss: 1.4792 - val_accuracy: 0.7587 - lr: 0.0010\n","Epoch 155/300\n","782/782 [==============================] - 31s 40ms/step - loss: 0.0307 - accuracy: 0.9897 - val_loss: 1.4757 - val_accuracy: 0.7605 - lr: 0.0010\n","Epoch 156/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.0289 - accuracy: 0.9905 - val_loss: 1.4817 - val_accuracy: 0.7589 - lr: 0.0010\n","Epoch 157/300\n","782/782 [==============================] - 34s 43ms/step - loss: 0.0297 - accuracy: 0.9901 - val_loss: 1.4834 - val_accuracy: 0.7600 - lr: 0.0010\n","Epoch 158/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.0280 - accuracy: 0.9912 - val_loss: 1.4916 - val_accuracy: 0.7615 - lr: 0.0010\n","Epoch 159/300\n","782/782 [==============================] - 31s 40ms/step - loss: 0.0281 - accuracy: 0.9913 - val_loss: 1.4779 - val_accuracy: 0.7608 - lr: 0.0010\n","Epoch 160/300\n","782/782 [==============================] - 32s 42ms/step - loss: 0.0280 - accuracy: 0.9909 - val_loss: 1.4858 - val_accuracy: 0.7593 - lr: 0.0010\n","Epoch 161/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.0286 - accuracy: 0.9901 - val_loss: 1.4799 - val_accuracy: 0.7588 - lr: 0.0010\n","Epoch 162/300\n","782/782 [==============================] - 31s 40ms/step - loss: 0.0260 - accuracy: 0.9916 - val_loss: 1.5030 - val_accuracy: 0.7610 - lr: 0.0010\n","Epoch 163/300\n","782/782 [==============================] - 33s 42ms/step - loss: 0.0278 - accuracy: 0.9907 - val_loss: 1.4881 - val_accuracy: 0.7605 - lr: 0.0010\n","Epoch 164/300\n","782/782 [==============================] - 34s 43ms/step - loss: 0.0258 - accuracy: 0.9915 - val_loss: 1.5107 - val_accuracy: 0.7611 - lr: 0.0010\n","Epoch 165/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.0268 - accuracy: 0.9910 - val_loss: 1.5222 - val_accuracy: 0.7600 - lr: 0.0010\n","Epoch 166/300\n","782/782 [==============================] - 31s 40ms/step - loss: 0.0266 - accuracy: 0.9913 - val_loss: 1.5211 - val_accuracy: 0.7595 - lr: 0.0010\n","Epoch 167/300\n","782/782 [==============================] - 33s 42ms/step - loss: 0.0261 - accuracy: 0.9914 - val_loss: 1.5210 - val_accuracy: 0.7619 - lr: 0.0010\n","Epoch 168/300\n","782/782 [==============================] - 32s 41ms/step - loss: 0.0251 - accuracy: 0.9915 - val_loss: 1.5156 - val_accuracy: 0.7619 - lr: 0.0010\n","Epoch 169/300\n","365/782 [=============>................] - ETA: 15s - loss: 0.0253 - accuracy: 0.9923"]}]}]}